{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96c9ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2b09097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_samples = 5\n",
    "max_concurrent_samples = 5\n",
    "\n",
    "source_dir = \"../mimicgen/datasets/source\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6ed09a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearOldFiles(task,difficulty,noise_clean):\n",
    "    # Step 1: Prepare the source files and remove old files\n",
    "    original_path = f\"../mimicgen/datasets/source/{task}.hdf5\"\n",
    "    os.makedirs(source_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    # Remove the existing source file if it exists\n",
    "    old_file = f\"{source_dir}/{task}_noise_{noise_clean}.hdf5\"\n",
    "    if os.path.exists(old_file):\n",
    "        os.remove(old_file)\n",
    "        print(f\"[✗] Removed old: {old_file}\")\n",
    "\n",
    "    # Remove old MimicGen output folders\n",
    "    output_root = f\"/tmp/core_datasets/{task}\"\n",
    "    folder = f\"{output_root}/{task}_D{difficulty}_noise_{noise_clean}\"\n",
    "    if os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"[✗] Removed old output: {folder}\")\n",
    "    \n",
    "    # Step 2: Create new noisy files\n",
    "    new_path = f\"{source_dir}/{task}_noise_{noise_clean}.hdf5\"\n",
    "    shutil.copyfile(original_path, new_path)\n",
    "    print(f\"[✓] Copied to: {new_path}\")\n",
    "    \n",
    "    return new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65c1c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise(new_path, noise):\n",
    "    # Add the noise to each action\n",
    "    with h5py.File(new_path, \"r+\") as f:\n",
    "        for key in f[\"data\"].keys():\n",
    "            actions = f[f\"data/{key}/actions\"][:]\n",
    "            injected_noise = np.random.normal(scale=noise, size=actions.shape)\n",
    "            f[f\"data/{key}/actions\"][:] = actions + injected_noise\n",
    "    print(f\"[✓] Added noise (scale={noise}) to: {new_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7357920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareSourceDataset(file_name, environment):\n",
    "    # for f in ../mimicgen/datasets/source/${TASK}_noisy_*.hdf5; do\n",
    "\n",
    "    command = [\n",
    "        \"python\",\n",
    "        \"../mimicgen/mimicgen/scripts/prepare_src_dataset.py\",\n",
    "        \"--dataset\", file_name,\n",
    "        \"--env_interface\", f\"MG_{environment}\",\n",
    "        \"--env_interface_type\", \"robosuite\"\n",
    "    ]\n",
    "\n",
    "    process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    print(f\"[✓] Prepared source dataset: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "798b5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupConfigs(task,difficulty,noise_clean,source_file):\n",
    "\n",
    "    # noisy_paths = sorted(glob.glob(f\"../mimicgen/datasets/source/{task}_noisy_*.hdf5\"))\n",
    "    # for i, path in enumerate(noisy_paths):\n",
    "\n",
    "    base_path = f\"/tmp/core_configs/demo_src_{task}_task_D{difficulty}.json\"\n",
    "    out_path = f\"/tmp/core_configs/demo_src_{task}_task_D{difficulty}_noise_{noise_clean}.json\"\n",
    "\n",
    "    with open(base_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Update dataset path and experiment name\n",
    "    config[\"experiment\"][\"source\"][\"dataset_path\"] = os.path.abspath(source_file)\n",
    "    config[\"experiment\"][\"name\"] = f\"{task}_D{difficulty}_noise_{noise_clean}\"\n",
    "    \n",
    "    config[\"experiment\"][\"render_video\"] = False\n",
    "    config[\"experiment\"][\"num_demo_to_render\"] = 0\n",
    "    config[\"experiment\"][\"num_fail_demo_to_render\"] = 0\n",
    "    \n",
    "    # Set number of trials dynamically\n",
    "    config[\"experiment\"][\"generation\"][\"num_trials\"] = num_samples\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "\n",
    "    print(f\"[✓] Wrote config: {out_path}\")\n",
    "    \n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2035a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(config_file, task, difficulty, noise_clean):\n",
    "    command = [\n",
    "        \"python\",\n",
    "        \"../mimicgen/mimicgen/scripts/generate_dataset.py\",\n",
    "        \"--config\", config_file,\n",
    "        \"--auto-remove-exp\",\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(f\"[✓] Generated dataset: {config_file}\")\n",
    "\n",
    "    data_file = f\"/tmp/core_datasets/{task}/{task}_D{difficulty}_noise_{noise_clean}/important_stats.json\"\n",
    "    with open(data_file) as f:\n",
    "        stats = json.load(f)\n",
    "        return stats.get(\"num_success\",\"0\"), stats.get(\"num_failures\",\"0\")\n",
    "    return \"0\",\"0\"\n",
    "    print(f\"[✓] Generated dataset: {data_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99b1b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputResults(task,difficulty,noise,successes,failures):\n",
    "\n",
    "    output_dir = \"../data_output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Open output_dir/{task}_D{difficulty}.csv using Pandas\n",
    "    output_file = f\"{output_dir}/{task}_D{difficulty}.csv\"\n",
    "    \n",
    "    # IF THE FILE EXISTS, open the CSV file and read it into a DataFrame\n",
    "    if os.path.exists(output_file):\n",
    "        df = pd.read_csv(output_file)\n",
    "        print(f\"[✓] Found existing CSV file: {output_file}\")\n",
    "    else:\n",
    "        # Create a new DataFrame with the specified columns\n",
    "        df = pd.DataFrame(columns=[\"noise\", \"success\", \"fail\"])\n",
    "        print(f\"[✓] Created new CSV file: {output_file}\")\n",
    "    # Add a new row to the DataFrame\n",
    "    new_row = {\n",
    "        \"noise\": noise,\n",
    "        \"success\": successes,\n",
    "        \"fail\": failures,\n",
    "    }\n",
    "\n",
    "    # Add the row to the DataFrame, and sort by noise ascending\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    df = df.sort_values(by=[\"noise\"], ascending=True)\n",
    "\n",
    "    # Save the dataframe to the CSV file (assume df already updated)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"[✓] Output results to: {output_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef824975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeInstruction(instruction):\n",
    "    task_items,noise = instruction\n",
    "    task, environment, difficulty = task_items\n",
    "    noise_clean = math.floor(noise*1000)\n",
    "\n",
    "    source_file = clearOldFiles(task,difficulty,noise_clean)\n",
    "    addNoise(source_file, noise)\n",
    "\n",
    "    # Use the subprocess to run the prepare_src_dataset.py script\n",
    "    prepareSourceDataset(source_file, environment)\n",
    "\n",
    "    config_file = setupConfigs(task,difficulty,noise_clean,source_file)\n",
    "\n",
    "    print(f\"[...] Generating dataset for {task} with noise level: {noise}\")\n",
    "    successes,failures = generateDataset(config_file, task, difficulty, noise_clean)\n",
    "    \n",
    "    outputResults(task,difficulty,noise,successes,failures)\n",
    "\n",
    "    print(f\"[✓] Finished processing {task} with noise levels: {noise}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4b0a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateInstructionList(instructions):\n",
    "    instruction_list = []\n",
    "    for instruction in instructions:\n",
    "        for noise in instruction[1]:\n",
    "            instruction_list.append((instruction[0],noise))\n",
    "    return instruction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7f721ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    [(\"kitchen\",\"Kitchen\",\"1\"),[0.00,0.01,0.02]],\n",
    "    [(\"coffee\",\"Coffee\",\"1\"),[0.05,0.10,0.15]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bdde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Running instruction 1/6: (('kitchen', 'Kitchen', '1'), 0.0)\n",
      "[✓] Running instruction 2/6: (('kitchen', 'Kitchen', '1'), 0.01)\n",
      "[✓] Running instruction 3/6: (('kitchen', 'Kitchen', '1'), 0.02)\n",
      "[✓] Running instruction 4/6: (('coffee', 'Coffee', '1'), 0.05)\n",
      "[✓] Running instruction 5/6: (('coffee', 'Coffee', '1'), 0.1)\n",
      "NOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\n",
      "\n",
      "To exit, you will have to explicitly quit this process, by either sending\n",
      "\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\n",
      "\n",
      "To read more about this, see https://github.com/ipython/ipython/issues/2049\n",
      "\n",
      "\n",
      "To connect another client to this kernel, use:\n",
      "    --existing kernel-1645315.json\n",
      "NOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\n",
      "\n",
      "To exit, you will have to explicitly quit this process, by either sending\n",
      "\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\n",
      "\n",
      "To read more about this, see https://github.com/ipython/ipython/issues/2049\n",
      "\n",
      "\n",
      "To connect another client to this kernel, use:\n",
      "    --existing kernel-1645317.json\n",
      "NOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\n",
      "\n",
      "To exit, you will have to explicitly quit this process, by either sending\n",
      "\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\n",
      "\n",
      "To read more about this, see https://github.com/ipython/ipython/issues/2049\n",
      "\n",
      "\n",
      "To connect another client to this kernel, use:\n",
      "    --existing kernel-1645318.json\n",
      "NOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\n",
      "\n",
      "To exit, you will have to explicitly quit this process, by either sending\n",
      "\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\n",
      "\n",
      "To read more about this, see https://github.com/ipython/ipython/issues/2049\n",
      "\n",
      "\n",
      "To connect another client to this kernel, use:\n",
      "    --existing kernel-1645316.json\n",
      "NOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\n",
      "\n",
      "To exit, you will have to explicitly quit this process, by either sending\n",
      "\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\n",
      "\n",
      "To read more about this, see https://github.com/ipython/ipython/issues/2049\n",
      "\n",
      "\n",
      "To connect another client to this kernel, use:\n",
      "    --existing kernel-1645319.json\n"
     ]
    }
   ],
   "source": [
    "instruction_list = generateInstructionList(instructions)\n",
    "complete_list = [False]*len(instruction_list)\n",
    "current_file = os.path.abspath(sys.argv[0])\n",
    "\n",
    "# Use subprocesses to run five instructions concurrently at a time, eventually getting through all instruction_list\n",
    "\n",
    "while True:\n",
    "    # Check if all instructions are complete\n",
    "    if all(complete_list):\n",
    "        print(\"[✓] All instructions completed.\")\n",
    "        break\n",
    "\n",
    "    # Get the next batch of instructions to run\n",
    "    processes = []\n",
    "    for i in range(len(instruction_list)):\n",
    "        if not complete_list[i]:\n",
    "            instruction = instruction_list[i]\n",
    "            print(f\"[✓] Running instruction {i+1}/{len(instruction_list)}: {instruction}\")\n",
    "            task_items, noise = instruction\n",
    "            task, environment, difficulty = task_items\n",
    "            p = subprocess.Popen([sys.executable, current_file, task, environment, difficulty, str(noise)], stdout=sys.stdout, stderr=sys.stderr)\n",
    "            processes.append(p)\n",
    "            complete_list[i] = True\n",
    "            if len(processes) >= max_concurrent_samples:\n",
    "                break\n",
    "\n",
    "    # Wait for the processes to finish\n",
    "    for p in processes:\n",
    "        p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1ce75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimicgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
